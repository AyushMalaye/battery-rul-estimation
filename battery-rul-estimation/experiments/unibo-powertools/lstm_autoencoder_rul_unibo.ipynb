{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# RUL estimation UNIBO Powertools Dataset"
   ],
   "metadata": {
    "id": "jw9FMur02UtZ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import math\n",
    "import os\n",
    "import ntpath\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "import sys\n",
    "import random\n",
    "\n",
    "from importlib import reload\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LSTM, Masking\n",
    "\n",
    "\n",
    "IS_COLAB = False\n",
    "IS_TRAINING = True\n",
    "RESULT_NAME = \"\"\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    data_path = \"/content/drive/My Drive/battery-state-estimation/battery-state-estimation/\"\n",
    "else:\n",
    "    data_path = \"../../\"\n",
    "\n",
    "sys.path.append(data_path)\n",
    "from data_processing.unibo_powertools_data import UniboPowertoolsData, CycleCols\n",
    "from data_processing.model_data_handler import ModelDataHandler\n",
    "from data_processing.prepare_rul_data import RulHandler"
   ],
   "outputs": [],
   "metadata": {
    "id": "XKxZ90kO2Uta"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Config logging"
   ],
   "metadata": {
    "id": "MfVCRISs2Utc"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "reload(logging)\n",
    "logging.basicConfig(format='%(asctime)s [%(levelname)s]: %(message)s', level=logging.DEBUG, datefmt='%Y/%m/%d %H:%M:%S')"
   ],
   "outputs": [],
   "metadata": {
    "id": "K2IvySBk2Utd"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {
    "id": "KsbkwTX22Utf"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dataset = UniboPowertoolsData(\n",
    "    test_types=[],\n",
    "    chunk_size=1000000,\n",
    "    lines=[37, 40],\n",
    "    charge_line=37,\n",
    "    discharge_line=40,\n",
    "    base_path=data_path\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/07/28 16:25:39 [DEBUG]: Start loading data with lines: [37, 40], types: [] and chunksize: 1000000...\n",
      "2021/07/28 16:26:18 [DEBUG]: Finish loading data.\n",
      "2021/07/28 16:26:18 [INFO]: Loaded raw dataset A data with cycle row count: 15384908 and capacity row count: 39585\n",
      "2021/07/28 16:26:18 [DEBUG]: Start cleaning cycle raw data...\n",
      "2021/07/28 16:26:33 [DEBUG]: Finish cleaning cycle raw data.\n",
      "2021/07/28 16:26:33 [INFO]: Removed 11 rows of abnormal cycle raw data.\n",
      "2021/07/28 16:26:33 [DEBUG]: Start cleaning capacity raw data...\n",
      "2021/07/28 16:26:33 [DEBUG]: Finish cleaning capacity raw data.\n",
      "2021/07/28 16:26:33 [INFO]: Removed 1 rows of abnormal capacity raw data.\n",
      "2021/07/28 16:26:33 [DEBUG]: Start assigning charging raw data...\n",
      "2021/07/28 16:26:34 [DEBUG]: Finish assigning charging raw data.\n",
      "2021/07/28 16:26:34 [INFO]: [Charging] cycle raw count: 12160812, capacity raw count: 19800\n",
      "2021/07/28 16:26:34 [DEBUG]: Start assigning discharging raw data...\n",
      "2021/07/28 16:26:35 [DEBUG]: Finish assigning discharging raw data.\n",
      "2021/07/28 16:26:35 [INFO]: [Discharging] cycle raw count: 3224085, capacity raw count: 19784\n"
     ]
    }
   ],
   "metadata": {
    "id": "DrHYRy-a2Utg"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "train_names = [\n",
    "    '000-DM-3.0-4019-S',#minimum capacity 1.48\n",
    "    '001-DM-3.0-4019-S',#minimum capacity 1.81\n",
    "    '002-DM-3.0-4019-S',#minimum capacity 2.06\n",
    "\n",
    "    '009-DM-3.0-4019-H',#minimum capacity 1.41\n",
    "    '010-DM-3.0-4019-H',#minimum capacity 1.44\n",
    "\n",
    "    '014-DM-3.0-4019-P',#minimum capacity 1.7\n",
    "    '015-DM-3.0-4019-P',#minimum capacity 1.76\n",
    "    '016-DM-3.0-4019-P',#minimum capacity 1.56\n",
    "    '017-DM-3.0-4019-P',#minimum capacity 1.29\n",
    "    #'047-DM-3.0-4019-P',#new 1.98\n",
    "    #'049-DM-3.0-4019-P',#new 2.19\n",
    "\n",
    "\n",
    "\n",
    "    '007-EE-2.85-0820-S',#2.5\n",
    "    '008-EE-2.85-0820-S',#2.49\n",
    "    '042-EE-2.85-0820-S',#2.51\n",
    "\n",
    "    '043-EE-2.85-0820-H',#2.31\n",
    "\n",
    "\n",
    "    '040-DM-4.00-2320-S',#minimum capacity 3.75, cycles 188\n",
    "\n",
    "\n",
    "    '018-DP-2.00-1320-S',#minimum capacity 1.82\n",
    "    #'019-DP-2.00-1320-S',#minimum capacity 1.61\n",
    "    '036-DP-2.00-1720-S',#minimum capacity 1.91\n",
    "    '037-DP-2.00-1720-S',#minimum capacity 1.84\n",
    "    '038-DP-2.00-2420-S',#minimum capacity 1.854 (to 0)\n",
    "    '050-DP-2.00-4020-S',#new 1.81\n",
    "    '051-DP-2.00-4020-S',#new 1.866    \n",
    "    \n",
    "]\n",
    "\n",
    "test_names = [\n",
    "    '003-DM-3.0-4019-S',#minimum capacity 1.84\n",
    "\n",
    "    '011-DM-3.0-4019-H',#minimum capacity 1.36\n",
    "\n",
    "    '013-DM-3.0-4019-P',#minimum capacity 1.6\n",
    "\n",
    "\n",
    "\n",
    "    '006-EE-2.85-0820-S',# 2.621\n",
    "    \n",
    "    '044-EE-2.85-0820-H',# 2.43\n",
    "\n",
    "\n",
    "\n",
    "    '039-DP-2.00-2420-S',#minimum capacity 1.93\n",
    "\n",
    "\n",
    "\n",
    "    '041-DM-4.00-2320-S',#minimum capacity 3.76, cycles 190\n",
    "]"
   ],
   "outputs": [],
   "metadata": {
    "id": "NSFp-2Rl2Utj"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "dataset.prepare_data(train_names, test_names)\n",
    "dataset_handler = ModelDataHandler(dataset, [\n",
    "    CycleCols.VOLTAGE,\n",
    "    CycleCols.CURRENT,\n",
    "    CycleCols.TEMPERATURE\n",
    "])\n",
    "\n",
    "rul_handler = RulHandler()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021/07/28 16:26:35 [DEBUG]: Start preparing data for training: ['000-DM-3.0-4019-S', '001-DM-3.0-4019-S'] and testing: ['003-DM-3.0-4019-S']...\n",
      "../../data_processing/unibo_powertools_data.py:273: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cyc_data = np.array(cyc_data)\n",
      "../../data_processing/unibo_powertools_data.py:273: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cyc_data = np.array(cyc_data)\n",
      "2021/07/28 16:26:44 [DEBUG]: Finish getting training and testing charge data.\n",
      "../../data_processing/unibo_powertools_data.py:273: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cyc_data = np.array(cyc_data)\n",
      "../../data_processing/unibo_powertools_data.py:273: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  cyc_data = np.array(cyc_data)\n",
      "2021/07/28 16:26:49 [DEBUG]: Finish getting training and testing discharge data.\n",
      "2021/07/28 16:26:49 [DEBUG]: Finish cleaning training and testing charge data.\n",
      "2021/07/28 16:26:49 [DEBUG]: Finish cleaning training and testing discharge data.\n",
      "2021/07/28 16:26:49 [DEBUG]: Finish adding training and testing discharge SOC parameters.\n",
      "2021/07/28 16:26:49 [DEBUG]: Finish adding training and testing discharge SOH parameters.\n",
      "2021/07/28 16:26:49 [DEBUG]: Finish preparing data.\n",
      "2021/07/28 16:26:49 [INFO]: Prepared training charge cycle data: (721,), capacity data: (721, 15)\n",
      "2021/07/28 16:26:49 [INFO]: Prepared testing charge cycle data: (356,), capacity data: (356, 15)\n",
      "2021/07/28 16:26:49 [INFO]: Prepared training discharge cycle data: (721,), capacity data: (721, 20)\n",
      "2021/07/28 16:26:49 [INFO]: Prepared testing discharge cycle data: (356,), capacity data: (356, 20)\n"
     ]
    }
   ],
   "metadata": {
    "id": "k-yTrXQ12Utm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preparation"
   ],
   "metadata": {
    "id": "bAAxueIqkZM9"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "CAPACITY_THRESHOLDS = {\n",
    "  3.0 : 2.7,#th 90% - min 2.1, 70%\n",
    "  2.85 : 2.7,#th 94.7% - min 2.622, 92%\n",
    "  2.0 : 1.93,#th 96.5% - min 1.93, 96.5%\n",
    "  4.0 : 3.77,#th 94.2% - min 3.77 94.2%\n",
    "  4.9 : 4.7,#th 95.9% - min 4.3, 87.7%\n",
    "  5.0 : 4.5#th 90% - min 3.63, 72.6%\n",
    "}\n",
    "N_CYCLE = 500\n",
    "WARMUP_TRAIN = 15\n",
    "WARMUP_TEST = 30\n",
    "\n",
    "(train_x, train_y_soh, test_x, test_y_soh,\n",
    "  train_battery_range, test_battery_range,\n",
    "  time_train, time_test, current_train, current_test) = dataset_handler.get_discharge_whole_cycle_future(train_names, test_names)\n",
    "\n",
    "train_x = train_x[:,:284,:]\n",
    "test_x = test_x[:,:284,:]\n",
    "print(\"cut train shape {}\".format(train_x.shape))\n",
    "print(\"cut test shape {}\".format(test_x.shape))\n",
    "\n",
    "x_norm = rul_handler.Normalization()\n",
    "train_x, test_x = x_norm.normalize(train_x, test_x)\n",
    "\n",
    "\n",
    "train_y = rul_handler.prepare_y_future(train_names, train_battery_range, train_y_soh, current_train, time_train, CAPACITY_THRESHOLDS)\n",
    "del globals()[\"current_train\"]\n",
    "del globals()[\"time_train\"]\n",
    "test_y = rul_handler.prepare_y_future(test_names, test_battery_range, test_y_soh, current_test, time_test, CAPACITY_THRESHOLDS)\n",
    "del globals()[\"current_test\"]\n",
    "del globals()[\"time_test\"]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "../../data_processing/model_data_handler.py:91: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x = np.array(\n",
      "2021/07/28 16:26:50 [INFO]: Train x: (721, 214, 3), train y soh: (721, 1) | Test x: (356, 214, 3), test y soh: (356, 1) | \n",
      "                            battery n cycle train: (2,), battery n cycle test: (1,), \n",
      "                            time train: (721, 214, 1), time test: (356, 214, 1) |\n",
      "                            raw current train: (721, 214), raw current test: (356, 214) |\n",
      "                            \n",
      "2021/07/28 16:26:50 [INFO]: battery step: [353 721]\n",
      "2021/07/28 16:26:50 [INFO]: battery ranges: [75542, 154294]\n",
      "2021/07/28 16:26:50 [INFO]: processing range 0 - 75542\n",
      "2021/07/28 16:26:50 [INFO]: processing range 75542 - 154294\n",
      "2021/07/28 16:26:50 [INFO]: Train integral: (721,)\n",
      "2021/07/28 16:26:50 [INFO]: processing range 0 - 353\n",
      "2021/07/28 16:26:50 [INFO]: threshold index: 148\n",
      "2021/07/28 16:26:50 [INFO]: processing range 353 - 721\n",
      "2021/07/28 16:26:50 [INFO]: threshold index: 512\n",
      "2021/07/28 16:26:50 [INFO]: y future: (721,)\n",
      "2021/07/28 16:26:50 [INFO]: y with future: (721, 2)\n",
      "2021/07/28 16:26:50 [INFO]: battery step: [356]\n",
      "2021/07/28 16:26:50 [INFO]: battery ranges: [76184]\n",
      "2021/07/28 16:26:50 [INFO]: processing range 0 - 76184\n",
      "2021/07/28 16:26:50 [INFO]: Train integral: (356,)\n",
      "2021/07/28 16:26:50 [INFO]: processing range 0 - 356\n",
      "2021/07/28 16:26:50 [INFO]: threshold index: 146\n",
      "2021/07/28 16:26:50 [INFO]: y future: (356,)\n",
      "2021/07/28 16:26:50 [INFO]: y with future: (356, 2)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cut train shape (721, 214, 3)\n",
      "cut test shape (356, 214, 3)\n"
     ]
    }
   ],
   "metadata": {
    "id": "TbntMzBZkZM9",
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## compressing x using autoencoder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "AUTOENCODER_WEIGHTS = '2021-07-19-17-29-18_autoencoder_unibo_powertools'\n",
    "\n",
    "# Model definition\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "LATENT_DIM = 10\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(train_x.shape[1], train_x.shape[2])),\n",
    "            #layers.MaxPooling1D(5, padding='same'),\n",
    "            layers.Conv1D(filters=16, kernel_size=5, strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv1D(filters=8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(self.latent_dim, activation='relu')\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Input(shape=(self.latent_dim)),\n",
    "            layers.Dense(568, activation='relu'),\n",
    "            layers.Reshape((71, 8)),\n",
    "            layers.Conv1DTranspose(filters=8, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv1DTranspose(filters=16, kernel_size=5, strides=2, activation='relu', padding='same'),\n",
    "            layers.Conv1D(3, kernel_size=3, activation='relu', padding='same'),\n",
    "            #layers.UpSampling1D(5),\n",
    "        ])\n",
    "\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder = Autoencoder(LATENT_DIM)\n",
    "autoencoder.compile(optimizer=opt, loss='mse', metrics=['mse', 'mae', 'mape', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "autoencoder.encoder.summary()\n",
    "autoencoder.decoder.summary()\n",
    "\n",
    "autoencoder.load_weights(data_path + 'results/trained_model/%s/model' % AUTOENCODER_WEIGHTS)\n",
    "\n",
    "\n",
    "# compression\n",
    "train_x = autoencoder.encoder(train_x).numpy()\n",
    "test_x = autoencoder.encoder(test_x).numpy()\n",
    "print(\"compressed train x shape {}\".format(train_x.shape))\n",
    "print(\"compressed test x shape {}\".format(test_x.shape))\n",
    "train_x = train_x[:,~np.all(train_x == 0, axis=0)]\n",
    "test_x = test_x[:,~np.all(test_x == 0, axis=0)]\n",
    "print(\"compressed test x shape without zero column {}\".format(test_x.shape))\n",
    "print(\"compressed test x shape without zero column {}\".format(test_x.shape))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 107, 16)           256       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 54, 8)             392       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 432)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                4330      \n",
      "=================================================================\n",
      "Total params: 4,978\n",
      "Trainable params: 4,978\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 568)               6248      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 71, 8)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose (Conv1DTran (None, 142, 8)            200       \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTr (None, 284, 16)           656       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 284, 3)            147       \n",
      "=================================================================\n",
      "Total params: 7,251\n",
      "Trainable params: 7,251\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Tensor's shape (568, 10) is not compatible with supplied shape (432, 10)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b2c6ae6fb363>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'results/trained_model/%s/model'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mAUTOENCODER_WEIGHTS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2204\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2205\u001b[0;31m       \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2206\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2207\u001b[0m         raise NotImplementedError(\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/training/tracking/util.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, save_path, options)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0mgraph_view\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_view\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m         options=options)\n\u001b[0;32m-> 1336\u001b[0;31m     base.CheckpointPosition(\n\u001b[0m\u001b[1;32m   1337\u001b[0m         checkpoint=checkpoint, proto_id=0).restore(self._graph_view.root)\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, trackable)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;31m# This object's correspondence with a checkpointed object is new, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m# process deferred restorations for it and its dependencies.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mrestore_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_restore_from_checkpoint_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrestore_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_restore_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrestore_ops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_restore_from_checkpoint_position\u001b[0;34m(self, checkpoint_position)\u001b[0m\n\u001b[1;32m    962\u001b[0m       \u001b[0mcurrent_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisit_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopleft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       new_restore_ops, new_tensor_saveables, new_python_saveables = (\n\u001b[0;32m--> 964\u001b[0;31m           \u001b[0mcurrent_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrackable\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    965\u001b[0m           ._single_restoration_from_checkpoint_position(\n\u001b[1;32m    966\u001b[0m               \u001b[0mcheckpoint_position\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_position\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_single_restoration_from_checkpoint_position\u001b[0;34m(self, checkpoint_position, visit_queue)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                                                []).append(child_position)\n\u001b[1;32m   1001\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mchild_position\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrackable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1003\u001b[0m           \u001b[0;31m# This object's correspondence is new, so dependencies need to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m           \u001b[0;31m# visited. Delay doing it so that we get a breadth-first dependency\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36mbind_object\u001b[0;34m(self, trackable)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_object\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_create_or_restore_slot_variable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m           optimizer_object._create_or_restore_slot_variable(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    303\u001b[0m               slot_variable_position=CheckpointPosition(\n\u001b[1;32m    304\u001b[0m                   \u001b[0mcheckpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_create_or_restore_slot_variable\u001b[0;34m(self, slot_variable_position, slot_name, variable)\u001b[0m\n\u001b[1;32m   1312\u001b[0m       initializer = trackable.CheckpointInitialValueCallable(\n\u001b[1;32m   1313\u001b[0m           checkpoint_position=slot_variable_position)\n\u001b[0;32m-> 1314\u001b[0;31m       slot_variable = self.add_slot(\n\u001b[0m\u001b[1;32m   1315\u001b[0m           \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m           \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36madd_slot\u001b[0;34m(self, var, slot_name, initializer)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_vars_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m         weight = tf_variables.Variable(\n\u001b[0m\u001b[1;32m    848\u001b[0m             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%s/%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v2_call\u001b[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maggregation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m       \u001b[0maggregation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariableAggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     return previous_getter(\n\u001b[0m\u001b[1;32m    245\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kws)\u001b[0m\n\u001b[1;32m    235\u001b[0m                         shape=None):\n\u001b[1;32m    236\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator_v2\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2652\u001b[0m   \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2654\u001b[0;31m   return resource_variable_ops.ResourceVariable(\n\u001b[0m\u001b[1;32m   2655\u001b[0m       \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m       \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1572\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_proto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimport_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimport_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1574\u001b[0;31m       self._init_from_args(\n\u001b[0m\u001b[1;32m   1575\u001b[0m           \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1576\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1710\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, shard_info)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# will get passed in by a functool.partial_wrapper in places like\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;31m# base_layer_utils.py's make_variable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     return CheckpointInitialValue(\n\u001b[0m\u001b[1;32m     82\u001b[0m         self._checkpoint_position, shape, shard_info=shard_info)\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, checkpoint_position, shape, shard_info)\u001b[0m\n\u001b[1;32m    115\u001b[0m       \u001b[0;31m# We need to set the static shape information on the initializer if\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m       \u001b[0;31m# possible so we don't get a variable with an unknown shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapped_value\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_checkpoint_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheckpoint_position\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shape\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m   1213\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m       raise ValueError(\n\u001b[0m\u001b[1;32m   1216\u001b[0m           \u001b[0;34m\"Tensor's shape %s is not compatible with supplied shape %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m           (self.shape, shape))\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor's shape (568, 10) is not compatible with supplied shape (432, 10)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_norm = rul_handler.Normalization()\n",
    "train_x, test_x = x_norm.normalize(train_x, test_x)\n",
    "train_x = rul_handler.battery_life_to_time_series(train_x, N_CYCLE, train_battery_range)\n",
    "test_x = rul_handler.battery_life_to_time_series(test_x, N_CYCLE, test_battery_range)\n",
    "\n",
    "train_x, train_y, train_battery_range, train_y_soh = rul_handler.delete_initial(train_x, train_y, train_battery_range, train_y_soh, WARMUP_TRAIN)\n",
    "test_x, test_y, test_battery_range, test_y_soh = rul_handler.delete_initial(test_x, test_y, test_battery_range, test_y_soh, WARMUP_TEST)\n",
    "\n",
    "# first one is SOH, we keep only RUL\n",
    "train_y = train_y[:,1]\n",
    "test_y = test_y[:,1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Y normalization"
   ],
   "metadata": {
    "id": "GskElnOAxTil"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "y_norm = rul_handler.Normalization()\n",
    "train_y, test_y = y_norm.normalize(train_y, test_y)"
   ],
   "outputs": [],
   "metadata": {
    "id": "5EOallNnxSpQ"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model training"
   ],
   "metadata": {
    "id": "7iYU-n0K2Utq"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if IS_TRAINING:\n",
    "    EXPERIMENT = \"lstm_autoencoder_rul_unibo_powertools\"\n",
    "\n",
    "    experiment_name = time.strftime(\"%Y-%m-%d-%H-%M-%S\") + '_' + EXPERIMENT\n",
    "    print(experiment_name)\n",
    "\n",
    "    # Model definition\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(lr=0.000003)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Masking(input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "    model.add(LSTM(128, activation='selu',\n",
    "                    return_sequences=True,\n",
    "                    kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(LSTM(64, activation='selu', return_sequences=False,\n",
    "                    kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(64, activation='selu', kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(32, activation='selu', kernel_regularizer=regularizers.l2(0.0002)))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(optimizer=opt, loss='huber', metrics=['mse', 'mae', 'mape', tf.keras.metrics.RootMeanSquaredError(name='rmse')])"
   ],
   "outputs": [],
   "metadata": {
    "id": "LSx96n4w2Uts"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if IS_TRAINING:\n",
    "    history = model.fit(train_x, train_y, \n",
    "                                epochs=500, \n",
    "                                batch_size=32, \n",
    "                                verbose=1,\n",
    "                                validation_split=0\n",
    "                               )"
   ],
   "outputs": [],
   "metadata": {
    "id": "AIEcv6Ey2Utu"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if IS_TRAINING:\n",
    "    model.save(data_path + 'results/trained_model/%s.h5' % experiment_name)\n",
    "\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_csv_file = data_path + 'results/trained_model/%s_history.csv' % experiment_name\n",
    "    with open(hist_csv_file, mode='w') as f:\n",
    "        hist_df.to_csv(f)\n",
    "    history = history.history"
   ],
   "outputs": [],
   "metadata": {
    "id": "oNHlqcvP2Utx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if not IS_TRAINING:\n",
    "    history = pd.read_csv(data_path + 'results/trained_model/%s_history.csv' % RESULT_NAME)\n",
    "    model = keras.models.load_model(data_path + 'results/trained_model/%s.h5' % RESULT_NAME)\n",
    "    model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if not IS_TRAINING:\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "        print(history)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Testing"
   ],
   "metadata": {
    "id": "LH5RANQIEQVx"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = model.evaluate(test_x, test_y, return_dict = True)\n",
    "print(results)\n",
    "max_rmse = 0\n",
    "for index in range(test_x.shape[0]):\n",
    "    result = model.evaluate(np.array([test_x[index, :, :]]), np.array([test_y[index]]), return_dict = True, verbose=0)\n",
    "    max_rmse = max(max_rmse, result['rmse'])\n",
    "print(\"Max rmse: {}\".format(max_rmse))"
   ],
   "outputs": [],
   "metadata": {
    "id": "ggNKW-VqENFN"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Results Visualization"
   ],
   "metadata": {
    "id": "uiqyD8Bn2Utz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=history['loss'],\n",
    "                    mode='lines', name='train'))\n",
    "fig.update_layout(title='Loss trend',\n",
    "                  xaxis_title='epoch',\n",
    "                  yaxis_title='loss',\n",
    "                  width=1400,\n",
    "                  height=600)\n",
    "fig.show()"
   ],
   "outputs": [],
   "metadata": {
    "id": "jH9RrBRN2Utz"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_predictions = model.predict(train_x)\n",
    "\n",
    "train_y = y_norm.denormalize(train_y)\n",
    "train_predictions = y_norm.denormalize(train_predictions)"
   ],
   "outputs": [],
   "metadata": {
    "id": "gtLOteXd-d6n"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = 0\n",
    "for b in train_battery_range:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=train_y_soh[a:b], y=train_predictions[a:b,0],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(x=train_y_soh[a:b], y=train_y[a:b],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on training',\n",
    "                    xaxis_title='SoH Capacity',\n",
    "                    yaxis_title='Remaining Ah until EOL',\n",
    "                    xaxis={'autorange':'reversed'},\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()\n",
    "    a = b"
   ],
   "outputs": [],
   "metadata": {
    "id": "ZsYMPQ0i2Ut1"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = 0\n",
    "for b in train_battery_range:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=train_predictions[a:b,0],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=train_y[a:b],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on training',\n",
    "                    xaxis_title='Cycle',\n",
    "                    yaxis_title='Remaining Ah until EOL',\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()\n",
    "    a = b"
   ],
   "outputs": [],
   "metadata": {
    "id": "Pe1Pzp04J1b5"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "test_predictions = model.predict(test_x)\n",
    "\n",
    "test_y = y_norm.denormalize(test_y)\n",
    "test_predictions = y_norm.denormalize(test_predictions)"
   ],
   "outputs": [],
   "metadata": {
    "id": "m0olyqr4-8BG"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = 0\n",
    "for b in test_battery_range:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=test_y_soh[a:b], y=test_predictions[a:b,0],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(x = test_y_soh[a:b], y=test_y[a:b],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on testing',\n",
    "                    xaxis_title='SoH Capacity',\n",
    "                    yaxis_title='Remaining Ah until EOL',\n",
    "                    xaxis={'autorange':'reversed'},\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()\n",
    "    a = b"
   ],
   "outputs": [],
   "metadata": {
    "id": "9U1MbGnq2Ut4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "a = 0\n",
    "for b in test_battery_range:\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=test_predictions[a:b, 0],\n",
    "                        mode='lines', name='predicted'))\n",
    "    fig.add_trace(go.Scatter(y=test_y[a:b],\n",
    "                        mode='lines', name='actual'))\n",
    "    fig.update_layout(title='Results on testing',\n",
    "                    xaxis_title='Cycle',\n",
    "                    yaxis_title='Remaining Ah until EOL',\n",
    "                    width=1400,\n",
    "                    height=600)\n",
    "    fig.show()\n",
    "    a = b"
   ],
   "outputs": [],
   "metadata": {
    "id": "uLEl8nALKAgJ"
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lstm_soh_prediction_only_future.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}